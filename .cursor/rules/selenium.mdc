# Selenium + Railway最適化ルール

## デプロイパターン選択指針

### 推奨パターン: Browserless Remote Driver

**Railway上でのSelenium実行において最も推奨される方法**

#### 利用場面
- 🎯 **本番環境での安定動作が必要**
- 🎯 **メンテナンス負荷を最小化したい**
- 🎯 **スケーラビリティが必要**
- 🎯 **デバッグツールが欲しい**

#### 実装パターン
```python
import os
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities

def setup_browserless_driver() -> webdriver.Remote:
    """Browserless remote driverの設定"""
    options = Options()
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    
    capabilities = DesiredCapabilities.CHROME
    capabilities['browserless:token'] = os.environ.get('BROWSERLESS_TOKEN')
    
    driver = webdriver.Remote(
        command_executor="https://chrome.browserless.io/webdriver",
        options=options,
        desired_capabilities=capabilities
    )
    return driver

def scrape_with_browserless(url: str) -> dict[str, str]:
    """Browserlessを使用したスクレイピング"""
    driver = None
    try:
        driver = setup_browserless_driver()
        driver.get(url)
        
        # スクレイピング処理
        title = driver.title
        
        return {"status": "success", "title": title, "url": url}
        
    except Exception as e:
        return {"status": "error", "error": str(e), "url": url}
    finally:
        if driver:
            driver.quit()
```

### 代替パターン: 同一コンテナ実行

**コスト重視または外部依存を避けたい場合**

#### 利用場面
- 💰 **コスト最優先**
- 🔒 **外部依存を避けたい**
- 📊 **軽量なスクレイピング**

#### Docker設定
```dockerfile
# Multi-stage build for optimization
FROM ghcr.io/astral-sh/uv:python3.12-bookworm-slim AS builder

# Install Chrome and ChromeDriver
RUN apt-get update && apt-get install -y \
    wget gnupg unzip curl && \
    wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | apt-key add - && \
    echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google.list && \
    apt-get update && \
    apt-get install -y google-chrome-stable && \
    rm -rf /var/lib/apt/lists/*

# Install ChromeDriver
RUN CHROMEDRIVER_VERSION=$(curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE) && \
    wget -N http://chromedriver.storage.googleapis.com/$CHROMEDRIVER_VERSION/chromedriver_linux64.zip && \
    unzip chromedriver_linux64.zip && \
    chmod +x chromedriver && \
    mv chromedriver /usr/local/bin/ && \
    rm chromedriver_linux64.zip

FROM builder AS production

# Environment variables
ENV PYTHONUNBUFFERED=1
ENV UV_COMPILE_BYTECODE=1
ENV DISPLAY=:99

# Create non-root user
RUN groupadd --gid 1000 appuser && \
    useradd --uid 1000 --gid 1000 --create-home appuser

WORKDIR /app
COPY pyproject.toml uv.lock ./
RUN uv sync --frozen --no-cache

COPY --chown=appuser:appuser src/ ./src/
USER appuser

CMD ["uv", "run", "app"]
```

#### 実装パターン
```python
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service

def setup_local_driver() -> webdriver.Chrome:
    """ローカルChrome driverの設定"""
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--remote-debugging-port=9222")
    
    service = Service("/usr/local/bin/chromedriver")
    
    driver = webdriver.Chrome(service=service, options=options)
    return driver

def scrape_with_local_driver(url: str) -> dict[str, str]:
    """ローカルdriverを使用したスクレイピング"""
    driver = None
    try:
        driver = setup_local_driver()
        driver.get(url)
        
        title = driver.title
        
        return {"status": "success", "title": title, "url": url}
        
    except Exception as e:
        return {"status": "error", "error": str(e), "url": url}
    finally:
        if driver:
            driver.quit()
```

## Railway設定

### railway.toml設定

```toml
[build]
builder = "DOCKERFILE"
dockerfilePath = "Dockerfile"

[deploy]
restartPolicyType = "ON_FAILURE"
sleepApplication = false
# 必要に応じてリソース制限
startCommand = "uv run app"

# Browserless使用時の環境変数
[[deploy.environmentVariables]]
name = "BROWSERLESS_TOKEN"
value = "${{BROWSERLESS_TOKEN}}"

[[deploy.environmentVariables]]
name = "ENVIRONMENT"
value = "production"
```

### 環境変数管理

```bash
# Browserless使用時
railway variables set BROWSERLESS_TOKEN="your-browserless-token"
railway variables set BROWSERLESS_ENDPOINT="https://chrome.browserless.io"

# 同一コンテナ使用時
railway variables set CHROME_DRIVER_PATH="/usr/local/bin/chromedriver"
railway variables set DISPLAY=":99"
```

## パフォーマンス最適化

### Browserless最適化

```python
import asyncio
from typing import List, Dict, Any
from concurrent.futures import ThreadPoolExecutor

class BrowserlessScrapingPool:
    """Browserless用並列スクレイピングプール"""
    
    def __init__(self, max_workers: int = 5):
        self.max_workers = max_workers
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
    
    def scrape_urls(self, urls: List[str]) -> List[Dict[str, Any]]:
        """複数URLの並列スクレイピング"""
        futures = [
            self.executor.submit(scrape_with_browserless, url) 
            for url in urls
        ]
        
        results = []
        for future in futures:
            try:
                result = future.result(timeout=30)
                results.append(result)
            except Exception as e:
                results.append({
                    "status": "error", 
                    "error": f"Timeout or error: {e}"
                })
        
        return results
```

### リソース管理

```python
from contextlib import contextmanager
from typing import Generator

@contextmanager
def managed_driver(driver_type: str = "browserless") -> Generator[webdriver.Remote, None, None]:
    """ドライバーのリソース管理"""
    driver = None
    try:
        if driver_type == "browserless":
            driver = setup_browserless_driver()
        else:
            driver = setup_local_driver()
        
        yield driver
        
    except Exception as e:
        logger.error(f"Driver error: {e}")
        raise
    finally:
        if driver:
            try:
                driver.quit()
            except Exception as e:
                logger.warning(f"Driver cleanup error: {e}")

# 使用例
def safe_scraping(url: str) -> dict[str, str]:
    """安全なスクレイピング実行"""
    with managed_driver("browserless") as driver:
        driver.get(url)
        return {"title": driver.title, "url": url}
```

## エラーハンドリング

### 堅牢なエラーハンドリング

```python
import time
from typing import Optional, Callable
from selenium.common.exceptions import (
    WebDriverException, 
    TimeoutException, 
    NoSuchElementException
)

def retry_on_failure(
    func: Callable, 
    max_retries: int = 3, 
    delay: float = 1.0
) -> Optional[dict]:
    """スクレイピング処理のリトライ機能"""
    
    for attempt in range(max_retries):
        try:
            return func()
            
        except (WebDriverException, TimeoutException) as e:
            logger.warning(f"Attempt {attempt + 1} failed: {e}")
            
            if attempt < max_retries - 1:
                time.sleep(delay * (2 ** attempt))  # Exponential backoff
                continue
            else:
                logger.error(f"All {max_retries} attempts failed")
                return {"status": "error", "error": str(e)}
                
        except Exception as e:
            logger.error(f"Unexpected error: {e}")
            return {"status": "error", "error": str(e)}

# 使用例
def robust_scraping(url: str) -> dict[str, str]:
    """堅牢なスクレイピング"""
    return retry_on_failure(
        lambda: scrape_with_browserless(url),
        max_retries=3
    )
```

## テスト戦略

### Browserlessテスト

```python
import pytest
from unittest.mock import Mock, patch

@pytest.fixture
def mock_browserless_driver():
    """Browserless driver のモック"""
    with patch("selenium.webdriver.Remote") as mock_driver:
        mock_instance = Mock()
        mock_driver.return_value = mock_instance
        yield mock_instance

def test_browserless_scraping_success(mock_browserless_driver):
    """Browserlessスクレイピング成功テスト"""
    # Arrange
    mock_browserless_driver.title = "Test Title"
    
    # Act
    result = scrape_with_browserless("https://example.com")
    
    # Assert
    assert result["status"] == "success"
    assert result["title"] == "Test Title"
    mock_browserless_driver.get.assert_called_once_with("https://example.com")
    mock_browserless_driver.quit.assert_called_once()

@pytest.mark.integration
def test_real_browserless_connection():
    """実際のBrowserless接続テスト"""
    if not os.getenv("BROWSERLESS_TOKEN"):
        pytest.skip("BROWSERLESS_TOKEN not set")
    
    result = scrape_with_browserless("https://httpbin.org/html")
    assert result["status"] == "success"
```

## モニタリングとロギング

### 構造化ログ

```python
import logging
import json
from typing import Dict, Any

def setup_scraping_logger() -> logging.Logger:
    """スクレイピング用ロガー設定"""
    logger = logging.getLogger("selenium_scraper")
    
    handler = logging.StreamHandler()
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)
    
    return logger

def log_scraping_metrics(
    url: str, 
    duration: float, 
    status: str, 
    details: Dict[str, Any] = None
) -> None:
    """スクレイピングメトリクスのログ"""
    metrics = {
        "url": url,
        "duration_seconds": duration,
        "status": status,
        "timestamp": time.time(),
        "details": details or {}
    }
    
    logger.info(f"Scraping metrics: {json.dumps(metrics)}")
```

## デバッグ支援

### Browserless Live Debugger活用

```python
def create_debug_session(url: str) -> str:
    """Browserless Live Debugger用セッション作成"""
    debug_options = Options()
    debug_options.add_argument("--remote-debugging-port=9222")
    
    capabilities = DesiredCapabilities.CHROME
    capabilities['browserless:token'] = os.environ.get('BROWSERLESS_TOKEN')
    capabilities['browserless:debug'] = True
    
    driver = webdriver.Remote(
        command_executor="https://chrome.browserless.io/webdriver",
        options=debug_options,
        desired_capabilities=capabilities
    )
    
    # デバッグ用URL生成
    session_id = driver.session_id
    debug_url = f"https://chrome.browserless.io/devtools/browser/{session_id}"
    
    print(f"Debug URL: {debug_url}")
    return debug_url
```

## ベストプラクティス

### 1. Driver選択の判断基準
- **Browserless**: 本番環境、高頻度、メンテナンス性重視
- **Local Driver**: 開発環境、低頻度、コスト重視

### 2. Railway最適化
- **Private networking活用**: 複数サービス間通信
- **Environment variables**: 設定の外部化
- **Resource limits**: 適切なリソース制限設定

### 3. セキュリティ
- **Token管理**: 環境変数でのトークン管理
- **ログ出力**: 機密情報の除外
- **エラーハンドリング**: 詳細エラー情報の制御
description:
globs:
alwaysApply: false
---
