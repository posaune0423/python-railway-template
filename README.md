# Python Railway Template - Selenium Standalone Chromium

Selenium Standalone Chromium ã‚’ä½¿ç”¨ã—ãŸ Remote WebDriver ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã§ã™ã€‚

## ğŸš€ ç‰¹å¾´

- **Selenium Standalone Chromium**: å®‰å®šã—ãŸãƒ­ãƒ¼ã‚«ãƒ« Docker ç’°å¢ƒ
- **Remote WebDriver**: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªåˆ†é›¢ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- **ARM64 (M1 Mac) å¯¾å¿œ**: seleniarm ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ç”¨
- **è‰²ä»˜ããƒ­ã‚°**: ANSIè‰²ã¨ã‚¢ã‚¤ã‚³ãƒ³ã«ã‚ˆã‚‹ç¾ã—ã„ãƒ­ã‚°å‡ºåŠ›
- **ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒ¼è¨­è¨ˆ**: ä¿å®ˆæ€§ã®é«˜ã„ã‚³ãƒ¼ãƒ‰æ§‹é€ 
- **å®šæ•°ç®¡ç†**: ä¸€å…ƒçš„ãªè¨­å®šå€¤ç®¡ç†
- **æ±ç”¨çš„ãªã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹**: å†åˆ©ç”¨å¯èƒ½ãª WebDriver ç®¡ç†

## ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
src/
â”œâ”€â”€ main.py              # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
â”œâ”€â”€ scraper.py           # WebDriverç®¡ç†ã‚¯ãƒ©ã‚¹ã¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°
â”œâ”€â”€ constants.py         # å®šæ•°ç®¡ç†ï¼ˆè¨­å®šå€¤ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç­‰ï¼‰
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ logger.py        # è‰²ä»˜ããƒ­ã‚¬ãƒ¼
â”œâ”€â”€ __init__.py
tests/
â””â”€â”€ test_main.py         # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
docker-compose.yml       # Selenium Standaloneæ§‹æˆ
Dockerfile               # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ãƒŠ
Makefile                 # ä¾¿åˆ©ãªã‚³ãƒãƒ³ãƒ‰é›†
```

## ğŸ¯ è¨­è¨ˆæ€æƒ³

### ã‚¯ãƒ©ã‚¹è¨­è¨ˆã®åˆ†é›¢
- **`StandaloneChromiumScraper`**: WebDriverã®ç®¡ç†ã«ç‰¹åŒ–ã—ãŸæ±ç”¨ã‚¯ãƒ©ã‚¹
  - æ¥ç¶šãƒ»åˆ‡æ–­ã®ç®¡ç†
  - åŸºæœ¬çš„ãªWebDriveræ“ä½œï¼ˆ`get_page`, `find_element`, `take_screenshot`ãªã©ï¼‰
  - Context Managerã«ã‚ˆã‚‹å®‰å…¨ãªãƒªã‚½ãƒ¼ã‚¹ç®¡ç†

- **å¤–éƒ¨é–¢æ•°**: ç‰¹å®šã®æ¥­å‹™ãƒ­ã‚¸ãƒƒã‚¯
  - `scrape_test_page()`: ãƒ†ã‚¹ãƒˆãƒšãƒ¼ã‚¸å›ºæœ‰ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯
  - ã‚¯ãƒ©ã‚¹ã¨ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã®è²¬ä»»åˆ†é›¢

### å®šæ•°ç®¡ç†
- **`constants.py`**: å…¨ã¦ã®è¨­å®šå€¤ã‚’ä¸€ç®‡æ‰€ã§ç®¡ç†
  - Seleniumè¨­å®šï¼ˆURLã€ãƒ–ãƒ©ã‚¦ã‚¶ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰
  - ãƒ–ãƒ©ã‚¦ã‚¶ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚ºã€User-Agentï¼‰
  - ãƒ­ã‚°è¨­å®šï¼ˆè‰²ã€ã‚¢ã‚¤ã‚³ãƒ³ã€ANSIåˆ¶å¾¡ã‚³ãƒ¼ãƒ‰ï¼‰
  - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆã‚¨ãƒ©ãƒ¼ã€æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰

## ğŸ› ï¸ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ä½¿ç”¨ä¾‹

```python
from scraper import StandaloneChromiumScraper, scrape_test_page

# æ±ç”¨çš„ãªWebDriverç®¡ç†
with StandaloneChromiumScraper() as scraper:
    # ãƒšãƒ¼ã‚¸å–å¾—
    scraper.get_page("https://example.com")
    
    # è¦ç´ æ¤œç´¢
    element = scraper.find_element(By.TAG_NAME, "h1")
    
    # ãƒšãƒ¼ã‚¸æƒ…å ±å–å¾—
    page_info = scraper.get_page_info()
    
    # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ
    scraper.take_screenshot("example.png")

# ç‰¹å®šã®æ¥­å‹™ãƒ­ã‚¸ãƒƒã‚¯
with StandaloneChromiumScraper() as scraper:
    result = scrape_test_page(scraper)
    print(result)
```

### Docker ã§ã®å®Ÿè¡Œ

```bash
# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œï¼ˆSeleniumèµ·å‹• + ã‚¢ãƒ—ãƒªå®Ÿè¡Œ + ãƒ­ã‚°è¡¨ç¤ºï¼‰
make scrape

# Selenium Standalone ã®ã¿èµ·å‹•
make start-selenium

# ãƒ­ã‚°è¡¨ç¤º
make logs
```

### ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™º

```bash
# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv sync

# Pythonå®Ÿè¡Œ
python -m src.main
```

## âš™ï¸ è¨­å®š

### ç’°å¢ƒå¤‰æ•°

```bash
SELENIUM_BROWSER=chrome          # chrome ã¾ãŸã¯ firefox
SELENIUM_REMOTE_URL=http://selenium:4444  # Dockerç’°å¢ƒ
# SELENIUM_REMOTE_URL=http://localhost:4444  # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ
```

### ãƒ–ãƒ©ã‚¦ã‚¶ã‚ªãƒ—ã‚·ãƒ§ãƒ³

`src/constants.py` ã§è¨­å®šã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º:

```python
# Chromeè¨­å®š
CHROME_WINDOW_SIZE = "1920,1080"
CHROME_USER_AGENT = "Mozilla/5.0 ..."

# Firefoxè¨­å®š  
FIREFOX_WINDOW_WIDTH = "1920"
FIREFOX_WINDOW_HEIGHT = "1080"

# ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
DEFAULT_TIMEOUT = 10  # ç§’
```

## ğŸ”§ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### æ–°ã—ã„ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°ã®è¿½åŠ 

```python
def scrape_custom_site(scraper: StandaloneChromiumScraper) -> dict:
    """ã‚«ã‚¹ã‚¿ãƒ ã‚µã‚¤ãƒˆã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°"""
    scraper.get_page("https://custom-site.com")
    scraper.wait_for_element(By.CLASS_NAME, "content")
    
    # æ¥­å‹™ãƒ­ã‚¸ãƒƒã‚¯
    data = {}
    elements = scraper.find_elements(By.CSS_SELECTOR, ".item")
    for element in elements:
        data[element.get_attribute("id")] = element.text
    
    return data
```

### å®šæ•°ã®è¿½åŠ 

```python
# constants.py ã«è¿½åŠ 
CUSTOM_SITE_URL = "https://custom-site.com"
CUSTOM_TIMEOUT = 15
CUSTOM_ERROR_MSG = "Custom site scraping failed: {}"
```

## ğŸ“Š ãƒ­ã‚°å‡ºåŠ›

è‰²ä»˜ããƒ­ã‚°ã§å®Ÿè¡ŒçŠ¶æ³ã‚’è¦–è¦šçš„ã«ç¢ºèª:

```
âœ… 2025-01-23 12:23:51 - INFO - Connected successfully! Browser: chrome 124.0
ğŸ•·ï¸ 2025-01-23 12:23:51 - INFO - Navigating to: https://httpbin.org/html  
ğŸ“¸ 2025-01-23 12:23:54 - INFO - Screenshot saved: reports/test_screenshot.png
âœ… 2025-01-23 12:23:54 - INFO - Test completed successfully!
```

## ğŸ§ª ãƒ†ã‚¹ãƒˆ

```bash
# Dockerå†…ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
docker run --rm python-railway-template-python-app python -m pytest tests/ -v

# ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
uv run pytest tests/ -v
```

## ğŸš¢ Railway ãƒ‡ãƒ—ãƒ­ã‚¤

1. GitHub ã«ãƒ—ãƒƒã‚·ãƒ¥
2. Railway ã§ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
3. ç’°å¢ƒå¤‰æ•°è¨­å®š:
   ```
   SELENIUM_REMOTE_URL=https://your-browserless-endpoint
   SELENIUM_BROWSER=chrome
   ```

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

1. **æ¥ç¶šã‚¨ãƒ©ãƒ¼**: Selenium Standalone ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª
   ```bash
   docker-compose up selenium-chrome
   ```

2. **ARM64 (M1 Mac) ã§ã®å•é¡Œ**: `seleniarm` ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ç”¨
   ```yaml
   # docker-compose.yml
   image: seleniarm/standalone-chromium:latest
   ```

3. **è¦ç´ ãŒè¦‹ã¤ã‹ã‚‰ãªã„**: é©åˆ‡ãªå¾…æ©Ÿã‚’è¿½åŠ 
   ```python
   scraper.wait_for_element(By.ID, "target-element")
   ```

### è¨­å®šç¢ºèª

```bash
# Selenium Grid çŠ¶æ…‹ç¢ºèª
curl http://localhost:4444/wd/hub/status

# VNC ã§ç”»é¢ç¢ºèª 
open vnc://localhost:5900
```

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License

## ğŸ¤ è²¢çŒ®

1. Fork the project
2. Create your feature branch
3. Commit your changes  
4. Push to the branch
5. Open a Pull Request
